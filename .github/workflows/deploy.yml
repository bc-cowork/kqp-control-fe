name: Build & Deploy + Package Offline (to S3)

on:
  push:
    branches: [main]
  release:
    types: [published]

permissions:
  contents: read
  id-token: write # needed for AWS OIDC

jobs:
  build-and-deploy:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Node 20.12.2
        uses: actions/setup-node@v4
        with:
          node-version: "20.12.2"

      # Create .env so build picks it up
      - name: Create .env for build
        run: |
          set -euo pipefail
          printf "NEXT_PUBLIC_SERVER_URL=http://141.164.63.141\n" > .env
          echo "Wrote .env:"
          cat .env

      # --- Build with npm (your request) ---
      - name: Install deps (npm, legacy peer deps)
        run: npm install --legacy-peer-deps

      - name: Build Next.js app
        env:
          NEXT_TELEMETRY_DISABLED: "1"
        run: |
          npx --yes next telemetry disable || true
          npm run build
          test -d .next || (echo ".next not found after build" && exit 1)

      # --- KEEP DEPLOYMENT AS-IS, but also send .env ---
      - name: Deploy to server
        env:
          DEPLOY_SERVER: ${{ secrets.DEPLOY_SERVER }}
          DEPLOY_USER: ${{ secrets.DEPLOY_USER }}
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }} # private key contents
          DEPLOY_PATH: ${{ secrets.DEPLOY_PATH }}
        run: |
          set -euo pipefail
          echo "$DEPLOY_KEY" > deploy_key
          chmod 600 deploy_key


          # Copy .next, package.json, package-lock.json, public, and .env
          rsync -avz --delete -e "ssh -i deploy_key -o StrictHostKeyChecking=no" \
            .next package.json package-lock.json public .env \
            "$DEPLOY_USER@$DEPLOY_SERVER:$DEPLOY_PATH/"

          ssh -i deploy_key -o StrictHostKeyChecking=no "$DEPLOY_USER@$DEPLOY_SERVER" "
            set -e
            cd '$DEPLOY_PATH' &&
            npm install --legacy-peer-deps &&
            (pm2 describe kqp-control-fe || pm2 start npm --name 'kqp-control-fe' -- start) &&
            pm2 restart kqp-control-fe
          "

      - name: Cleanup key
        if: always()
        run: rm -f deploy_key

  package_offline:
    name: Package Offline Tar (npm) â†’ S3
    runs-on: ubuntu-latest
    if: github.event_name == 'release' && github.event.action == 'published'

    steps:
      - name: Checkout release tag
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.release.tag_name }}

      - name: Set up Node 20.12.2
        uses: actions/setup-node@v4
        with:
          node-version: "20.12.2"

      - name: Prepare repo-local npm cache
        run: mkdir -p .offline-cache/npm

      # Create .env so it's included in the offline bundle
      - name: Create .env for offline package
        run: |
          set -euo pipefail
          printf "NEXT_PUBLIC_SERVER_URL=http://141.164.63.141\nPORT=8083" > .env
          echo "Wrote .env for packaging:"
          cat .env

      # Install deps and build ON CI so node_modules + .next are baked into the tar
      - name: Install deps & build (npm)
        env:
          NEXT_TELEMETRY_DISABLED: "1"
        run: |
          set -euo pipefail
          npm install --legacy-peer-deps
          npx --yes next telemetry disable || true
          npm run build
          # quick checks
          test -d node_modules || (echo "node_modules missing" && exit 1)
          test -d .next || (echo ".next missing" && exit 1)
          node -p "process.platform + ' ' + process.arch"

      # Create a stable snapshot that INCLUDES node_modules and .next
      - name: Stage a clean snapshot for tar (includes node_modules)
        run: |
          set -euo pipefail
          rm -rf .offline-stage
          mkdir -p .offline-stage
          rsync -a --delete \
            --exclude ".git" \
            --exclude ".github" \
            --exclude ".offline-stage" \
            --exclude "*.tar.gz" \
            ./ .offline-stage/

      - name: Create offline tarball
        run: |
          set -euo pipefail
          TAR="kqp-control-fe-offline-npm.tar.gz"
          echo "Creating $TAR from .offline-stage ..."
          tar -C .offline-stage -czf "$TAR" .
          ls -lh "$TAR"

      # Optional: keep a copy attached to the workflow for quick download
      - name: Upload tar as workflow artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: kqp-control-fe-offline-npm
          path: kqp-control-fe-offline-npm.tar.gz
          if-no-files-found: error

      # --- Upload tar to S3 using your OIDC role + bucket ---
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload offline tarball to S3 (versioned + latest)
        env:
          BUCKET: ${{ secrets.S3_BUCKET }}
        run: |
          set -euo pipefail
          TAR="kqp-control-fe-offline-npm.tar.gz"
          DATE="$(date -u +'%Y-%m-%dT%H-%M-%SZ')"
          SHA="${GITHUB_SHA::7}"
          PREFIX="kqp-control-fe"   # adjust if you prefer a different prefix

          KEY="${PREFIX}/${DATE}/${SHA}/${TAR}"
          LATEST_KEY="${PREFIX}/latest/${TAR}"

          # Server-side encryption with S3-managed keys
          ENC_ARGS="--sse AES256"

          echo "Uploading to s3://${BUCKET}/${KEY}"
          aws s3 cp "$TAR" "s3://${BUCKET}/${KEY}" --only-show-errors $ENC_ARGS --content-type application/gzip

          echo "Updating 'latest'"
          aws s3 cp "$TAR" "s3://${BUCKET}/${LATEST_KEY}" --only-show-errors $ENC_ARGS --content-type application/gzip

      - name: Output S3 locations + presigned URL (7 days) for latest
        env:
          BUCKET: ${{ secrets.S3_BUCKET }}
        run: |
          TAR="kqp-control-fe-offline-npm.tar.gz"
          DATE="$(date -u +'%Y-%m-%dT%H-%M-%SZ')"
          SHA="${GITHUB_SHA::7}"
          PREFIX="kqp-control-fe"
          KEY="${PREFIX}/${DATE}/${SHA}/${TAR}"
          LATEST_KEY="${PREFIX}/latest/${TAR}"

          echo "Stored:"
          echo "  s3://${BUCKET}/${KEY}"
          echo "  s3://${BUCKET}/${LATEST_KEY}"

          echo "Presigned (7 days):"
          aws s3 presign "s3://${BUCKET}/${LATEST_KEY}" --expires-in 604800